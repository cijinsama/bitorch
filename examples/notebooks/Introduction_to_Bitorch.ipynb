{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Hello there! In this notebook the advantages of Binary Neural Networks are explored and compared to networks utilizing full precision calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Neural Networks\n",
    "\n",
    "The main difference between common neural networks and bnns is the use of 1 bit weights and quantization functions on the input data. This allows us to take advantage of highly optimizable binary operations in order to speed up the learning and inference of the neural networks.\n",
    "\n",
    "Per default we use the sign function to transform floating point inputs and weights to it's binary value:\n",
    "\n",
    "$$ sign(x) = \\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t+1  & \\mbox{if } x \\geq 0 \\\\\n",
    "\t\t-1 & \\mbox{if } x < 0\n",
    "\t\\end{array}\n",
    "\\right. $$\n",
    "\n",
    "When computing gradients, we use a so called Straight Through Estimator (STE). Also gradients are automatically canceled if they get to big due to the fact that changes in already very large gradients have no effect when applying the sign function above. This gives us the following quantization behaviour for a real number $r$ passing through our quantized layers ($q$ is the quantized value, $c$ is a given loss value, $t_{clip}$ the gradient cancellation threshold):\n",
    "\n",
    "$$\n",
    "\\text{Forward}: q = sign(r)\\\\\n",
    "\\text{Backward}: \\frac{\\delta c}{\\delta q} = \\frac{\\delta c}{\\delta r} 1_{|r| \\leq t_{clip}}\n",
    "$$\n",
    "\n",
    "Now let's see how our layers compare with full precision layers when used in a simple modle. For this we will build a full precision LeNet and compare its performance with our binarized LeNet version when trained on the MNIST-Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "First we need to import some packages to be ready to go..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything imported!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.animation\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import mnist\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from bitorch.layers import (\n",
    "    QLinear,\n",
    "    QActivation,\n",
    "    QConv2d_NoAct,\n",
    "    WeightGraphicalDebug\n",
    ")\n",
    "\n",
    "print(\"everything imported!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train on the MNIST dataset, containing a collection of handwritten digits. For this we first download the dataset and then create loaders for training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = mnist.MNIST(root='./train', train=True, transform=ToTensor(), download=True)\n",
    "test_dataset = mnist.MNIST(root='./test', train=False, transform=ToTensor(), download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to build a Model. At first we will create a full precision LeNet version. Bitorch comes with an included WeightGraphicalDebug layer to output weight tensors. Below the implementation of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_convolution_features = 64\n",
    "num_linear_nodes = 1000\n",
    "num_output_nodes = 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # first convolution block\n",
    "    nn.Conv2d(1, num_convolution_features, kernel_size=5),\n",
    "    nn.BatchNorm2d(num_convolution_features),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "\n",
    "    # second convolution blocks\n",
    "    WeightGraphicalDebug(\n",
    "        nn.Conv2d(num_convolution_features, num_convolution_features, kernel_size=5),\n",
    "        num_outputs = 10\n",
    "    ),\n",
    "    nn.BatchNorm2d(num_convolution_features),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "\n",
    "    nn.Linear(num_convolution_features * 4 * 4, num_output_nodes),\n",
    "    nn.BatchNorm1d(num_output_nodes),\n",
    "    nn.Tanh(),\n",
    "\n",
    "    nn.Linear(num_output_nodes, num_output_nodes),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice LeNet consists of two convolution blocks containing a convolution and a batchnorm layer, an tanh activation function and a max pool layer, followed by one blocks with linear units to classify the features retrieved from the prior layers.\n",
    "\n",
    "We want to catch the weights of the second convolution block, so we wrap the convolution layer in our weight debug layer. later we will create and pass matplotlib objects to this layer in order to create graphical output.\n",
    "\n",
    "Now lets train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(params=model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "# this part is for graphic output (still a bit hacky)\n",
    "fig = plt.figure()\n",
    "axes = [plt.subplot(2, 5, i) for i in range(1, 11)]\n",
    "example_img = torch.zeros((3, 3))\n",
    "example_img[0][0] = 1.0\n",
    "images = [ax.imshow(example_img, cmap='gray') for ax in axes]\n",
    "\n",
    "# set graphic objects in debug layer\n",
    "debug_layer = model[4]\n",
    "debug_layer.set_figure(fig)\n",
    "debug_layer.set_images(images)\n",
    "\n",
    "# we also want the loss to be plotted in a graph\n",
    "fig2, ax2 = plt.subplots()\n",
    "loss_plot = None\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for idx, (x_train, y_train) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat = model(x_train)\n",
    "        loss = criterion(y_hat, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if idx % 100 == 0 and idx > 0:\n",
    "            print(f\"    Loss in epoch {epoch + 1} for batch {idx}: {epoch_loss / idx}\")\n",
    "    epoch_loss /= len(train_loader)\n",
    "    \n",
    "    losses.append(epoch_loss)\n",
    "    loss_plot = ax2.plot(losses)\n",
    "    fig2.canvas.draw()\n",
    "    print(\"total loss of epoch\", epoch+1, \":\", epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see as the loss declines the full precision feature maps vary a bit in shade.\n",
    "\n",
    "Below we evaluate how well our full precision network performs on a test dataset by calculating its accuarcy when confronted with previously unseen examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0.0\n",
    "# now validate model with test dataset\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in test_loader:\n",
    "\n",
    "        y_hat = model(x_test)\n",
    "        test_loss += criterion(y_hat, y_test).item()\n",
    "\n",
    "        # determine count of correctly predicted labels\n",
    "        predictions = torch.argmax(y_hat, dim=1)\n",
    "        correct += torch.sum(y_test == predictions).item()\n",
    "test_loss /= len(test_loader)\n",
    "accuracy = correct / (len(test_loader) * test_loader.batch_size)\n",
    "print(\"test loss:\", test_loss, \"test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the full precision version we achieve an accuracy of ~98%-99%.\n",
    "\n",
    "Next, we want to evaluate the performance of our binary layers by first building a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_convolution_features = 64\n",
    "num_linear_nodes = 1000\n",
    "num_output_nodes = 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # first convolution block\n",
    "    nn.Conv2d(1, num_convolution_features, kernel_size=5),\n",
    "    nn.BatchNorm2d(num_convolution_features),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "\n",
    "    # second convolution blocks\n",
    "    # previously: Conv2d(num_convolution_features, num_convolution_features, kernel_size=5),\n",
    "    QActivation(),\n",
    "    WeightGraphicalDebug(\n",
    "        QConv2d_NoAct(num_convolution_features, num_convolution_features, kernel_size=5),\n",
    "        num_outputs=10),\n",
    "    nn.BatchNorm2d(num_convolution_features),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "\n",
    "    # previously: Linear(num_convolution_features * 4 * 4, num_linear_nodes)\n",
    "    QActivation(),\n",
    "    QLinear(num_convolution_features * 4 * 4, num_linear_nodes),\n",
    "    nn.BatchNorm1d(num_linear_nodes),\n",
    "    nn.Tanh(),\n",
    "\n",
    "    nn.Linear(num_linear_nodes, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the quantized LeNet version above we simply exchanged the convolution, linear and activation layers starting from the second convolution block with our corresponding quantized versions.\n",
    "\n",
    "Note that we also added an additional activation layer in front of the convolution and linear layers. This is necessary because we want to pass already binarized input values to our quantized layers. We want the network to learn on binarized data, so it would not make much sense to pass full precision input values to a layer with binarized weights.\n",
    "\n",
    "The default QConv2d layer from bittorch already includes this activation layer but for better understanding we used the dedicated QConv2d_NoAct version here.\n",
    "\n",
    "Now we train this model using the exact same code as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(params=model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "# this part is for graphic output (still a bit hacky)\n",
    "fig = plt.figure()\n",
    "axes = [plt.subplot(2, 5, i) for i in range(1, 11)]\n",
    "example_img = torch.zeros((3, 3))\n",
    "example_img[0][0] = 1.0\n",
    "images = [ax.imshow(example_img, cmap='gray') for ax in axes]\n",
    "\n",
    "# set graphic objects in debug layer\n",
    "debug_layer = model[5]\n",
    "debug_layer.set_figure(fig)\n",
    "debug_layer.set_images(images)\n",
    "\n",
    "# we also want the loss to be plotted in a graph\n",
    "fig2, ax2 = plt.subplots()\n",
    "loss_plot = None\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for idx, (x_train, y_train) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat = model(x_train)\n",
    "        loss = criterion(y_hat, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if idx % 100 == 0 and idx > 0:\n",
    "            print(f\"    Loss in epoch {epoch + 1} for batch {idx}: {epoch_loss / idx}\")\n",
    "    epoch_loss /= len(train_loader)\n",
    "    \n",
    "    losses.append(epoch_loss)\n",
    "    loss_plot = ax2.plot(losses)\n",
    "    fig2.canvas.draw()\n",
    "    print(\"total loss of epoch\", epoch+1, \":\", epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we also evaluate the performance of our quantized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0.0\n",
    "# now validate model with test dataset\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in test_loader:\n",
    "\n",
    "        y_hat = model(x_test)\n",
    "        test_loss += criterion(y_hat, y_test).item()\n",
    "\n",
    "        # determine count of correctly predicted labels\n",
    "        predictions = torch.argmax(y_hat, dim=1)\n",
    "        correct += torch.sum(y_test == predictions).item()\n",
    "test_loss /= len(test_loader)\n",
    "accuracy = correct / (len(test_loader) * test_loader.batch_size)\n",
    "print(\"test loss:\", test_loss, \"test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the binarized version of LeNet performs slightly worse than the full precision version. But considering that we reduced the number of possible weight and input values from full precision (i.e. 2^32 possible values) to binary (2 possible values) the loss of accuracy is astonishingly small.\n",
    "\n",
    "With some further tweaks to the binarized LeNet version we are able to reduce this accuracy gap to less than 1-2% while still only working on a 2-bit network.\n",
    "\n",
    "Our bittorch framework does not yet contain the implementations of speed up operations to fully utilize the binarized feature maps but it already demonstrates the potential performance gains of binary neural networks while still competing with state-of-the-art full precision networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5  ('venv': venv)",
   "language": "python",
   "name": "pythonjvsc74a57bd08fb575bd3668c7feb9d8766cc49fe669c9d659f4adfa19403bdb21fe513e262d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "33dc79d9c93c4173d950decc21eec4d15a5a0691c11f926d77002524a8c01a4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
